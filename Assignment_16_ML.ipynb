{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da84d245",
   "metadata": {},
   "source": [
    "### 1. In a linear equation, what is the difference between a dependent variable and an independent variable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d57ae",
   "metadata": {},
   "source": [
    "An independent variable, also known as the input variable or the explanatory variable, is a variable that is intentionally manipulated or controlled in an experiment or analysis. It is the variable that is considered to be the cause or driver of changes in other variables. In the context of a linear equation, the independent variable is typically represented on the x-axis of a graph.\n",
    "\n",
    "A dependent variable, also known as the output variable or the response variable, is a variable that is observed or measured to assess the effect or outcome of changes in the independent variable. It is the variable that is influenced by the independent variable and is the one being predicted, explained, or analyzed. In the context of a linear equation, the dependent variable is typically represented on the y-axis of a graph.\n",
    "\n",
    "In a linear equation, the relationship between the dependent variable and the independent variable is expressed as a straight line, where changes in the independent variable are associated with proportional changes in the dependent variable. \n",
    "\n",
    "The equation takes the form y = mx + c, where y represents the dependent variable, x represents the independent variable, m represents the slope of the line, and c represents the y-intercept (the value of y when x is zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c8421e",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aff073",
   "metadata": {},
   "source": [
    "### 2. What is the concept of simple linear regression? Give a specific example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a15d57",
   "metadata": {},
   "source": [
    "Simple linear regression is a statistical technique used to model and analyze the relationship between two variables: a dependent variable (also known as the response variable) and an independent variable (also known as the predictor variable). It assumes that the relationship between the variables can be represented by a straight line.\n",
    "\n",
    "Suppose we want to study the relationship between the number of hours studied (independent variable) and the exam scores obtained (dependent variable) by a group of students. We collect data from 10 students, recording the number of hours they studied and their corresponding exam scores.\n",
    "\n",
    "- Hours Studied (x): [4, 6, 7, 8, 10, 12, 14, 16, 18, 20]\n",
    "- Exam Scores (y): [60, 70, 75, 80, 90, 85, 95, 90, 92, 98]\n",
    "\n",
    "We can use simple linear regression to determine the relationship between the number of hours studied and the exam scores. By fitting a line to this data, we can estimate the slope and y-intercept of the line. The resulting equation might be:\n",
    "\n",
    "Exam Scores (y) = 5.2 * Hours Studied (x) + 53.8\n",
    "\n",
    "Using this equation, we can make predictions about exam scores based on the number of hours studied. For example, if a student studied for 15 hours, we can estimate their exam score to be:\n",
    "\n",
    "Exam Scores (y) = 5.2 * 15 + 53.8 = 133.8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef9d50",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679d5fd",
   "metadata": {},
   "source": [
    "### 3. In a linear regression, define the slope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da565c02",
   "metadata": {},
   "source": [
    "In linear regression, the slope represents the rate of change in the dependent variable (y) per unit change in the independent variable (x). It quantifies the steepness or incline of the regression line, which represents the relationship between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56839f86",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316bc87f",
   "metadata": {},
   "source": [
    "### 4. Determine the graph&#39;s slope, where the lower point on the line is represented as (3, 2) and the higher point is represented as (2, 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c85e3b",
   "metadata": {},
   "source": [
    "Mathematically, the slope is denoted by the symbol \"m\" and is calculated using the formula:\n",
    "\n",
    "m = (Σ((x - x̄) * (y - ȳ))) / Σ((x - x̄)²)\n",
    "\n",
    "x̄ = 3+2/2 = 2.5\n",
    "ȳ = 2+2/2 = 2\n",
    "\n",
    "Σ((x - x̄) = (3-2.5) + (2-2.5)\n",
    "= 0.5 - 0.5 \n",
    "= 0 \n",
    "\n",
    "Judging by the first part to be zero we can caculate the answer is 0.\n",
    "\n",
    "m is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f8930",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dbccc8",
   "metadata": {},
   "source": [
    "### 5. In linear regression, what are the conditions for a positive slope?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e781e0",
   "metadata": {},
   "source": [
    "In linear regression, the condition for a positive slope is that the relationship between the independent variable(s) or \"x\" and the dependent variable or \"y\" is such that an increase in the independent variable(s) leads to an increase in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce670b56",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da5a4b",
   "metadata": {},
   "source": [
    "### 6. In linear regression, what are the conditions for a negative slope?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a8a587",
   "metadata": {},
   "source": [
    "In linear regression, the condition for a negative slope is that the relationship between the independent variable(s) and the dependent variable is such that an increase in the independent variable(s) leads to a decrease in the dependent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299690c",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6729df23",
   "metadata": {},
   "source": [
    "### 7. What is multiple linear regression and how does it work?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1608a",
   "metadata": {},
   "source": [
    "Multiple linear regression is an extension of simple linear regression that involves predicting a dependent variable (response variable) based on multiple independent variables (predictor variables). It aims to model the relationship between the dependent variable and the independent variables by fitting a linear equation to the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633c874",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d648d79d",
   "metadata": {},
   "source": [
    "### 8. In multiple linear regression, define the number of squares due to error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe3ce44",
   "metadata": {},
   "source": [
    "The sum of squares due to error (SSE) represents the variation in the dependent variable that is not explained by the independent variables in the model. It quantifies the discrepancy between the observed values of the dependent variable and the predicted values obtained from the regression equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4bb4b5",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22db84",
   "metadata": {},
   "source": [
    "### 9. In multiple linear regression, define the number of squares due to regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f15c6",
   "metadata": {},
   "source": [
    "In multiple linear regression, the sum of squares due to regression (SSR) represents the variation in the dependent variable that is explained by the independent variables in the model. It quantifies the amount of variability in the dependent variable that can be attributed to the linear relationship with the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91907a",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142b76b",
   "metadata": {},
   "source": [
    "### 10. In a regression equation, what is multicollinearity?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b58f6",
   "metadata": {},
   "source": [
    "Multicollinearity refers to a high degree of correlation or linear dependency between two or more independent variables (predictor variables) in a regression equation. It occurs when the independent variables are not independent of each other, which can pose challenges in interpreting the regression model and estimating the individual effects of the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c7bd8",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c2a13",
   "metadata": {},
   "source": [
    "### 11. What is heteroskedasticity, and what does it mean?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e894456",
   "metadata": {},
   "source": [
    "Heteroskedasticity refers to a violation of the assumption of homoscedasticity in regression analysis. Homoscedasticity assumes that the error terms or residuals in a regression model have constant variance across all levels of the independent variables. In contrast, heteroskedasticity occurs when the variability of the error terms is not constant across the range of the independent variables.\n",
    "\n",
    "In simpler terms, heteroskedasticity means that the spread or dispersion of the residuals is not the same throughout the range of the independent variables. This can result in uneven scatter or a funnel-shaped pattern when plotting the residuals against the predicted values or the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d135eb",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe9c6a",
   "metadata": {},
   "source": [
    "### 12. Describe the concept of ridge regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4ef60",
   "metadata": {},
   "source": [
    "Ridge regression is a technique used in linear regression analysis to address the issue of multicollinearity, which occurs when there is a high correlation among the independent variables. It is a regularization method that adds a penalty term to the ordinary least squares (OLS) objective function to mitigate the impact of multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b472fc0e",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d54c27",
   "metadata": {},
   "source": [
    "### 13. Describe the concept of lasso regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182cad4",
   "metadata": {},
   "source": [
    "Lasso regression, short for \"Least Absolute Shrinkage and Selection Operator,\" is another regularization technique used in linear regression to address multicollinearity and perform variable selection. Similar to ridge regression, lasso regression adds a penalty term to the ordinary least squares (OLS) objective function, but with a different form of regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde455a",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3db7b",
   "metadata": {},
   "source": [
    "### 14. What is polynomial regression and how does it work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7587408",
   "metadata": {},
   "source": [
    "Polynomial regression is a form of regression analysis that models the relationship between the independent variable(s) and the dependent variable with a polynomial function. It is an extension of simple linear regression that allows for curved relationships between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3e6dbc",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d84f08d",
   "metadata": {},
   "source": [
    "### 15. Describe the basis function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159625d",
   "metadata": {},
   "source": [
    "A basis function, in the context of regression analysis and machine learning, refers to a set of functions used to represent or approximate the relationship between the independent variables and the dependent variable. Basis functions are typically used in non-linear regression models to capture complex patterns and relationships that cannot be adequately represented by simple linear functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b32a40",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2f95f",
   "metadata": {},
   "source": [
    "\n",
    "### 16. Describe how logistic regression works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef8ac9",
   "metadata": {},
   "source": [
    "Logistic regression is a popular statistical method used for binary classification, where the dependent variable (or outcome) is binary or categorical. It estimates the probability of an event occurring based on the values of independent variables. Although it is named \"regression,\" logistic regression is actually a classification algorithm rather than a regression algorithm. The logistic regression model is evaluated using various metrics such as accuracy, precision, recall, F1 score, and area under the receiver operating characteristic curve (AUC-ROC), depending on the specific problem and requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
