{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd702219",
   "metadata": {},
   "source": [
    "### 1. Provide an example of the concepts of Prior, Posterior, and Likelihood?\n",
    "\n",
    "Example: To determine whether a person has a certain medical condition based on a diagnostic test. In this example, we'll use the concepts of prior, posterior, and likelihood.\n",
    "\n",
    "Prior: The prior probability represents our initial belief or knowledge about the likelihood of a person having the medical condition before any diagnostic test results are considered. Let's say we know from previous studies that the prevalence of this condition in the general population is 5%. So, our prior probability of someone having the condition would be 0.05 (or 5%).\n",
    "\n",
    "Likelihood: The likelihood is the probability of observing a certain test result given that the person has or does not have the medical condition. Let's assume that the diagnostic test has been evaluated, and its accuracy is known. For simplicity, let's say that the test has a sensitivity of 90%, meaning it correctly identifies 90% of the individuals who have the condition, and a specificity of 95%, meaning it correctly identifies 95% of the individuals who do not have the condition.\n",
    "\n",
    "Now, let's consider a hypothetical person and calculate the likelihoods:\n",
    "\n",
    "If the person has the medical condition, the test will correctly identify them as positive with a probability of 0.9 (sensitivity).\n",
    "\n",
    "If the person does not have the medical condition, the test will correctly identify them as negative with a probability of 0.95 (specificity).\n",
    "\n",
    "Posterior: The posterior probability is the updated probability of a person having the medical condition after taking into account the prior probability and the test result. It is calculated using Bayes' theorem:\n",
    "Posterior probability = (Prior probability * Likelihood) / Evidence\n",
    "\n",
    "Let's say the person takes the test, and it comes out positive. We can now calculate the posterior probability of them having the condition using the prior probability and likelihood mentioned earlier:\n",
    "\n",
    "Posterior probability = (0.05 * 0.9) / Evidence\n",
    "\n",
    "The evidence is the probability of obtaining a positive test result, regardless of whether the person has the condition or not. We can calculate the evidence by considering both the true positives and false positives:\n",
    "\n",
    "Evidence = (Prior probability * Sensitivity) + ((1 - Prior probability) * (1 - Specificity))\n",
    "\n",
    "Finally, by plugging in the values, we can calculate the posterior probability.\n",
    "\n",
    "This example demonstrates how the prior probability, likelihood, and posterior probability are interconnected in the context of diagnostic testing and how they can be used to update our beliefs based on new information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1fdcd",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781f669e",
   "metadata": {},
   "source": [
    "### 2. What role does Bayes&#39; theorem play in the concept learning principle?\n",
    "\n",
    "Bayes' theorem plays a fundamental role in the concept learning principle by providing a mathematical framework for updating our beliefs or probabilities based on new evidence or observations. The concept learning principle is a cognitive process through which individuals acquire knowledge and learn new concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbfcf38",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad9ea4",
   "metadata": {},
   "source": [
    "### 3. Offer an example of how the Nave Bayes classifier is used in real life.\n",
    "\n",
    "One practical example of how the Naive Bayes classifier is used in real life is in email spam filtering. Email providers and clients often employ Naive Bayes classifiers to automatically categorize incoming emails as either spam or non-spam (ham) based on their content and other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb298f9",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9dc0b",
   "metadata": {},
   "source": [
    "### 4. Can the Naive Bayes classifier be used on continuous numeric data? If so, how can you go about doing it?\n",
    "\n",
    "Yes, the Naive Bayes classifier can be used on continuous numeric data. However, it requires an assumption about the distribution of the data. One common approach is to assume that the continuous features follow a Gaussian (normal) distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ff3a6",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63caa311",
   "metadata": {},
   "source": [
    "### 5. What are Bayesian Belief Networks, and how do they work? What are their applications? Are they capable of resolving a wide range of issues?\n",
    "\n",
    "Bayesian Belief Networks (BBNs), also known as Bayesian Networks or Probabilistic Graphical Models, are powerful tools for modeling uncertain knowledge and making probabilistic inferences. They combine probability theory with graphical models to represent complex relationships between variables and capture the dependencies among them.\n",
    "\n",
    "Applications of Bayesian Belief Networks:\n",
    "\n",
    "Decision Support Systems: BBNs are used in decision support systems to model complex decision-making processes under uncertainty. They help in assessing the impact of various decisions and uncertainties on outcomes and aid in making informed decisions.\n",
    "\n",
    "Medical Diagnosis: BBNs are widely used in medical diagnosis to model the relationships between symptoms, diseases, and test results. They can help in determining the likelihood of different diseases given observed symptoms and test results.\n",
    "\n",
    "Risk Assessment: BBNs are employed in risk assessment and risk management in various domains, such as finance, engineering, and environmental sciences. They can model the dependencies among different risk factors and assess the overall risk based on available evidence.\n",
    "\n",
    "Natural Language Processing: BBNs are utilized in natural language processing tasks, such as text classification, sentiment analysis, and information extraction. They can capture the probabilistic relationships between words, topics, and sentiments in textual data.\n",
    "\n",
    "BBNs have a broad range of applications across domains where uncertainty and probabilistic reasoning are essential. However, their effectiveness depends on the availability of accurate data, domain knowledge, and the appropriate modeling of the relationships among variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac76e3",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f37b073",
   "metadata": {},
   "source": [
    "### 6. Passengers are checked in an airport screening system to see if there is an intruder. Let I be the random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98 and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered, implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) = 0.00001. What are the chances that an alarm would be triggered when an individual is actually an intruder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72613d88",
   "metadata": {},
   "source": [
    "To determing the chances that the alarm would be triggered when an intruder is actually an intruder, we need to calculate conditional probability (P(I = 1|A = 1)).\n",
    "\n",
    "We use Baye's theorem to do this:\n",
    "P(I = 1|A = 1) = P(A = 1|I = 1) * (P(I=1/P(A=1))\n",
    "\n",
    "We know:\n",
    "\n",
    "P(A = 1|I = 1) = 0.98 (probability of detecting an intruder)\n",
    "P(A = 1|I = 0) = 1-0.98 = 0.001 (probability of detecting non-intruder)\n",
    "P(I = 1) = 0.00001 (likelihood of an intruder)\n",
    "\n",
    "Let's calculate P(A = 1) using law of total probability\n",
    "P(A = 1) = P(A = 1|I = 1) * P(I = 1) + P(A = 1|I = 0) * P(I = 0)\n",
    "\n",
    "Since P(I = 0) = 1 - P(I = 1), we can substitute this value:\n",
    "P(A = 1) = P(A = 1|I = 1) * P(I = 1) + P(A = 1|I = 0) * (1 - P(I = 1))\n",
    "\n",
    "Let's substitute these values in the above formula.\n",
    "\n",
    "P(I = 1|A = 1) =  P(A = 1|I = 1) * P(I = 1) / [P(A = 1|I = 1) * P(I = 1) + P(A = 1|I = 0) * (1 - P(I = 1))]\n",
    "\n",
    "P(I = 1|A = 1) = 0.98 * 0.00001 /[(0.98 * 0.00001) + (0.001 * 1-0.00001)]\n",
    "\n",
    "P(I = 1|A = 1) â‰ˆ 0.0098\n",
    "\n",
    "Therefore the chances that the alarm will be triggered is approx 0.98%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2708520",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cca579",
   "metadata": {},
   "source": [
    "### 7. An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune (random variable D)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a24ca0",
   "metadata": {},
   "source": [
    "To calculate the likelihood that a person who tests positive is actually immune (random variable D), we need to use Bayes' theorem.\n",
    "\n",
    "Let's define the following variables:\n",
    "\n",
    "D: Person is immune to the antibiotic (event of interest)\n",
    "\n",
    "T: Test result is positive\n",
    "\n",
    "DÌ…: Person is not immune to the antibiotic (complement of D)\n",
    "\n",
    "TÌ…: Test result is negative (complement of T)\n",
    "\n",
    "\n",
    "We are given the following information:\n",
    "\n",
    "P(T = 1 | DÌ… = 1) = 0.01 (false positive rate, probability of a positive test given that the person is not immune)\n",
    "\n",
    "P(T = 0 | D = 1) = 0.05 (false negative rate, probability of a negative test given that the person is immune)\n",
    "\n",
    "P(D = 1) = 0.02 (probability of a person being immune)\n",
    "\n",
    "We want to calculate P(D = 1 | T = 1), the probability of a person being immune given that they have tested positive.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "P(D = 1 | T = 1) = (P(T = 1 | D = 1) * P(D = 1)) / P(T = 1)\n",
    "\n",
    "To calculate P(T = 1), we can use the law of total probability:\n",
    "P(T = 1) = P(T = 1 | D = 1) * P(D = 1) + P(T = 1 | DÌ… = 1) * P(DÌ… = 1)\n",
    "\n",
    "P(T = 1) = 0.05 * 0.02 + 0.01 * (1 - 0.02)\n",
    "P(T = 1) = 0.001 + 0.0098\n",
    "P(T = 1) = 0.0108\n",
    "\n",
    "Now we can substitute these values into the Bayes' theorem equation:\n",
    "P(D = 1 | T = 1) = (0.01 * 0.02) / 0.0108\n",
    "P(D = 1 | T = 1) = 0.0002 / 0.0108\n",
    "P(D = 1 | T = 1) â‰ˆ 0.0185\n",
    "\n",
    "Therefore, the likelihood that a person who tests positive is actually immune to the antibiotic is approximately 0.0185 or 1.85%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be21448",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b252aa3",
   "metadata": {},
   "source": [
    "### 8. In order to prepare for the test, a student knows that there will be one question in the exam that is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and 50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10 type B problems, and 6 of 10 type C problems.\n",
    "\n",
    "1. What is the likelihood that the student can solve the exam problem?\n",
    "\n",
    "2. Given the student&#39;s solution, what is the likelihood that the problem was of form A?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dfb8ba",
   "metadata": {},
   "source": [
    "We are given the following probabilities:\n",
    "\n",
    "P(A) = 0.30 (probability of the problem being of type A)\n",
    "\n",
    "P(B) = 0.20 (probability of the problem being of type B)\n",
    "\n",
    "P(C) = 0.50 (probability of the problem being of type C)\n",
    "\n",
    "Let's denote the event of solving the problem correctly as \"D\".\n",
    "\n",
    "P(D|A) = Probability of solving a type A problem correctly\n",
    "P(D|B) = Probability of solving a type B problem correctly\n",
    "P(D|C) = Probability of solving a type C problem correctly\n",
    "\n",
    "We know:\n",
    "\n",
    "For type A problems (P(D|A) = 0.90\n",
    "For type B problems (P(D|B) = 0.20\n",
    "For type C problems (P(D|C) = 0.60\n",
    "\n",
    "To calculate probability of solving a problem correctly is:\n",
    "P(D) = P(D|A) * P(A) + P(D|B) * P(B) + P(D|C) * P(C)\n",
    "\n",
    "P(D) = (0.90 * 0.30) + (0.20 * 0.20) + (0.50 * 0.60)\n",
    "P(D) = 0.27 + 0.04 + 0.30\n",
    "P(D) = 0.61\n",
    "\n",
    "To calculate likelihood that the problem was of form A we use Baye's theorem.\n",
    "P(A|D) = (P(D|A) * P(A)) / P(D)\n",
    "P(A|D) = (0.90 * 0.30) / 0.61\n",
    "0.4426\n",
    "\n",
    "Therefore the likelihood that a problem was of form A is 44.26%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa6d89",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ab4e3e",
   "metadata": {},
   "source": [
    "### 9. A bank installs a CCTV system to track and photograph incoming customers. Despite the constant influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "\n",
    "1. How many customers come into the bank on a daily basis (10 hours)?\n",
    "\n",
    "2. On a daily basis, how many fake photographs (photographs taken when there is no customer) and how many missed photographs (photographs taken when there is a customer) are there?\n",
    "\n",
    "3. Explain likelihood that there is a customer if there is a photograph?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21666dfa",
   "metadata": {},
   "source": [
    "#### 1. To determing the number of customers come into the bank on a daily basis we need to calculate the number of 5min blocks in 10 hours and then multiply it to the prob of a customer arriving in each time period.\n",
    "\n",
    "#### 10 hrs * 60 mins per hour = 600 mins in total\n",
    "#### 600/5 = 120 time periods.\n",
    "\n",
    "#### The probability of a customer arriving in each time period is 0.05. Therefore the probability of customers coming into bank on a daily basis is 120th time periods * 0.05 = 6 customers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb293548",
   "metadata": {},
   "source": [
    "#### 2. To calculate the number of fake photographs and missed photographs on a daily basis, we need to consider the probabilities of these events occurring in each time period and sum them up for all time periods.\n",
    "\n",
    "Probability of false photograph when there is no customer = 0.10\n",
    "Probability of missed photograph is 100-99 = 1 or 0.01\n",
    "\n",
    "Since time period has an independent probability we can multiply the probabilities by the # of time periods.\n",
    "\n",
    "number of fake photographs = 120 * 0.10 = 12 \n",
    "number of missed photographs = 120 * 0.01 = 1.2\n",
    "\n",
    "Since you can't have .2 photograph we round it to the nearest whole number which is 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1eeba",
   "metadata": {},
   "source": [
    "#### 3. Let's use Baye's theorem to calculate this.\n",
    "\n",
    "Let's denote the event of a customer being present as \"C\" and the event of a photograph being taken as \"P.\"\n",
    "P(C) = 5% or 0.05 (probability of a customer arriving in each time period)\n",
    "P(P|C) = 99% or 0.99 (probability of a photograph being taken if a customer is present)\n",
    "P(P|~C) = 10% or 0.10 (probability of a photograph being taken if there is no customer)\n",
    "\n",
    "We need to calculate P(C|P), which is the probability of a customer being present given that a photograph was taken.\n",
    "\n",
    "#### P(C|P) = (P(P|C) * P(C)) / [ P(P|C) * P(C) + P (P| ~C) * P( ~C) ]\n",
    "\n",
    "= (0.99 * 0.05) / [ 0.99 * 0.05) + (0.10 * 0.95)]\n",
    "= 0.34 \n",
    "\n",
    "Therefore the likelihood that there is a customer if there is a photograph is approx 34%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e292597e",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdef8e6",
   "metadata": {},
   "source": [
    "### 10. Create the conditional probability table associated with the node Won Toss in the Bayesian Belief network to represent the conditional independence assumptions of the Naive Bayes classifier for the match winning prediction problem in Section 6.4.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf658aec",
   "metadata": {},
   "source": [
    "Assuming we have two possible outcomes for the \"Won Toss\" node: \"Yes\" and \"No,\" and we have other features (or nodes) in the classifier that are conditionally independent given the \"Won Toss\" outcome, we can define the conditional probabilities as follows:\n",
    "\n",
    "- Won Toss   | P(Won Toss)\n",
    "- Yes/No     | p (1-p)\n",
    "\n",
    "Here, p represents the probability of winning the toss. The assumption is that the outcome of the toss is independent of other features in the classifier.\n",
    "\n",
    "This conditional probability table reflects the Naive Bayes assumption that each feature is conditionally independent given the class variable (in this case, the outcome of the toss)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
